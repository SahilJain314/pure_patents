{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corpus.pkl', 'just_text.csv', 'patent_raw.csv']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import gensim\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "data_path = \"D:MachineLearning/PURE_patents/\"\n",
    "os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3930271</td>\n",
       "      <td>Golf glove. A golf glove is disclosed having a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3930272</td>\n",
       "      <td>Crib leg lock. A lock for a height-adjustable ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3930273</td>\n",
       "      <td>Bed safety side rail arrangement. A bed safety...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3930274</td>\n",
       "      <td>Assembly for use in recreational activities. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3930275</td>\n",
       "      <td>Method of fabricating a slipper. A novel slipp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3930276</td>\n",
       "      <td>Wheel spinning and vehicle conveying apparatus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3930277</td>\n",
       "      <td>Mobile floor sweeper. A Mobile Floor Sweeper i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3930278</td>\n",
       "      <td>Paintbrush and guard attachment for edging. A ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3930279</td>\n",
       "      <td>Rubber windshield wiper blades having increase...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3930280</td>\n",
       "      <td>Bottle insert for product container. Leaks are...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                                                  1\n",
       "0  3930271  Golf glove. A golf glove is disclosed having a...\n",
       "1  3930272  Crib leg lock. A lock for a height-adjustable ...\n",
       "2  3930273  Bed safety side rail arrangement. A bed safety...\n",
       "3  3930274  Assembly for use in recreational activities. T...\n",
       "4  3930275  Method of fabricating a slipper. A novel slipp...\n",
       "5  3930276  Wheel spinning and vehicle conveying apparatus...\n",
       "6  3930277  Mobile floor sweeper. A Mobile Floor Sweeper i...\n",
       "7  3930278  Paintbrush and guard attachment for edging. A ...\n",
       "8  3930279  Rubber windshield wiper blades having increase...\n",
       "9  3930280  Bottle insert for product container. Leaks are..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patents = pd.read_csv(data_path + 'patent_raw.csv', header = None)\n",
    "patents.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Patent:\n",
      "Golf glove. A golf glove is disclosed having an extra finger pocket between the index and middle finger pockets for securing one finger of one hand of a golf player between the fingers of the player's other hand.\n"
     ]
    }
   ],
   "source": [
    "print('First Patent:\\n' + patents.iloc[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "just_text = patents[1] \n",
    "just_text.head()\n",
    "just_text.to_csv(data_path+'just_text.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4966215\n"
     ]
    }
   ],
   "source": [
    "just_text = pd.read_csv(data_path + 'just_text.csv')\n",
    "print(just_text.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Golf glove. A golf glove is disclosed having a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crib leg lock. A lock for a height-adjustable ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bed safety side rail arrangement. A bed safety...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Assembly for use in recreational activities. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Method of fabricating a slipper. A novel slipp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   1\n",
       "0  Golf glove. A golf glove is disclosed having a...\n",
       "1  Crib leg lock. A lock for a height-adjustable ...\n",
       "2  Bed safety side rail arrangement. A bed safety...\n",
       "3  Assembly for use in recreational activities. T...\n",
       "4  Method of fabricating a slipper. A novel slipp..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "just_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7018019it [10:10, 11486.84it/s]\n"
     ]
    }
   ],
   "source": [
    "import smart_open\n",
    "\n",
    "def read_corpus(fname, tokens_only=False):\n",
    "    with smart_open.open(fname, encoding=\"iso-8859-1\") as f:\n",
    "        for i, line in tqdm(enumerate(f)):\n",
    "            tokens = gensim.utils.simple_preprocess(line)\n",
    "            if tokens_only:\n",
    "                yield tokens\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield gensim.models.doc2vec.TaggedDocument(tokens, [i])\n",
    "\n",
    "train_corpus = list(read_corpus(data_path + \"just_text.csv\"))\n",
    "#test_corpus = list(read_corpus(lee_test_file, tokens_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(data_path+'train_corpus.pkl', 'wb') as f:\n",
    "    pickle.dump(train_corpus, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_corpus[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-25 23:08:36,617 : INFO : PROGRESS: at example #6650000, processed 523507297 words (6374307/s), 379493 word types, 6650000 tags\n",
      "2020-10-25 23:08:36,778 : INFO : PROGRESS: at example #6660000, processed 524471659 words (6042110/s), 379779 word types, 6660000 tags\n",
      "2020-10-25 23:08:36,944 : INFO : PROGRESS: at example #6670000, processed 525512163 words (6307575/s), 380057 word types, 6670000 tags\n",
      "2020-10-25 23:08:37,103 : INFO : PROGRESS: at example #6680000, processed 526487437 words (6167592/s), 380377 word types, 6680000 tags\n",
      "2020-10-25 23:08:37,264 : INFO : PROGRESS: at example #6690000, processed 527496421 words (6275677/s), 380674 word types, 6690000 tags\n",
      "2020-10-25 23:08:37,422 : INFO : PROGRESS: at example #6700000, processed 528494651 words (6362347/s), 380986 word types, 6700000 tags\n",
      "2020-10-25 23:08:37,580 : INFO : PROGRESS: at example #6710000, processed 529488234 words (6332426/s), 381317 word types, 6710000 tags\n",
      "2020-10-25 23:08:37,740 : INFO : PROGRESS: at example #6720000, processed 530483066 words (6247504/s), 381622 word types, 6720000 tags\n",
      "2020-10-25 23:08:37,903 : INFO : PROGRESS: at example #6730000, processed 531519873 words (6387768/s), 381921 word types, 6730000 tags\n",
      "2020-10-25 23:08:38,062 : INFO : PROGRESS: at example #6740000, processed 532525169 words (6366944/s), 382266 word types, 6740000 tags\n",
      "2020-10-25 23:08:38,227 : INFO : PROGRESS: at example #6750000, processed 533530251 words (6133118/s), 382587 word types, 6750000 tags\n",
      "2020-10-25 23:08:38,389 : INFO : PROGRESS: at example #6760000, processed 534531071 words (6181934/s), 382922 word types, 6760000 tags\n",
      "2020-10-25 23:08:38,551 : INFO : PROGRESS: at example #6770000, processed 535558344 words (6397959/s), 383228 word types, 6770000 tags\n",
      "2020-10-25 23:08:38,705 : INFO : PROGRESS: at example #6780000, processed 536531921 words (6337492/s), 383621 word types, 6780000 tags\n",
      "2020-10-25 23:08:38,869 : INFO : PROGRESS: at example #6790000, processed 537571881 words (6388474/s), 383899 word types, 6790000 tags\n",
      "2020-10-25 23:08:39,022 : INFO : PROGRESS: at example #6800000, processed 538529851 words (6277888/s), 384246 word types, 6800000 tags\n",
      "2020-10-25 23:08:39,188 : INFO : PROGRESS: at example #6810000, processed 539567705 words (6286001/s), 384519 word types, 6810000 tags\n",
      "2020-10-25 23:08:39,348 : INFO : PROGRESS: at example #6820000, processed 540580738 words (6356437/s), 384807 word types, 6820000 tags\n",
      "2020-10-25 23:08:39,509 : INFO : PROGRESS: at example #6830000, processed 541569021 words (6168283/s), 385105 word types, 6830000 tags\n",
      "2020-10-25 23:08:39,665 : INFO : PROGRESS: at example #6840000, processed 542549873 words (6329645/s), 385387 word types, 6840000 tags\n",
      "2020-10-25 23:08:39,837 : INFO : PROGRESS: at example #6850000, processed 543584738 words (6039776/s), 385667 word types, 6850000 tags\n",
      "2020-10-25 23:08:39,998 : INFO : PROGRESS: at example #6860000, processed 544596927 words (6316599/s), 385970 word types, 6860000 tags\n",
      "2020-10-25 23:08:40,154 : INFO : PROGRESS: at example #6870000, processed 545584065 words (6363401/s), 386283 word types, 6870000 tags\n",
      "2020-10-25 23:08:40,314 : INFO : PROGRESS: at example #6880000, processed 546552971 words (6118140/s), 386583 word types, 6880000 tags\n",
      "2020-10-25 23:08:40,481 : INFO : PROGRESS: at example #6890000, processed 547601429 words (6288467/s), 386883 word types, 6890000 tags\n",
      "2020-10-25 23:08:40,637 : INFO : PROGRESS: at example #6900000, processed 548596870 words (6416805/s), 387178 word types, 6900000 tags\n",
      "2020-10-25 23:08:40,791 : INFO : PROGRESS: at example #6910000, processed 549582459 words (6426460/s), 387478 word types, 6910000 tags\n",
      "2020-10-25 23:08:40,963 : INFO : PROGRESS: at example #6920000, processed 550627086 words (6119601/s), 387723 word types, 6920000 tags\n",
      "2020-10-25 23:08:41,119 : INFO : PROGRESS: at example #6930000, processed 551616759 words (6353800/s), 388067 word types, 6930000 tags\n",
      "2020-10-25 23:08:41,282 : INFO : PROGRESS: at example #6940000, processed 552606785 words (6138805/s), 388348 word types, 6940000 tags\n",
      "2020-10-25 23:08:41,438 : INFO : PROGRESS: at example #6950000, processed 553590657 words (6363708/s), 388623 word types, 6950000 tags\n",
      "2020-10-25 23:08:41,604 : INFO : PROGRESS: at example #6960000, processed 554621064 words (6199853/s), 388909 word types, 6960000 tags\n",
      "2020-10-25 23:08:41,760 : INFO : PROGRESS: at example #6970000, processed 555619637 words (6433685/s), 389193 word types, 6970000 tags\n",
      "2020-10-25 23:08:41,918 : INFO : PROGRESS: at example #6980000, processed 556599671 words (6254484/s), 389531 word types, 6980000 tags\n",
      "2020-10-25 23:08:42,078 : INFO : PROGRESS: at example #6990000, processed 557623066 words (6447813/s), 389839 word types, 6990000 tags\n",
      "2020-10-25 23:08:42,237 : INFO : PROGRESS: at example #7000000, processed 558605347 words (6188778/s), 390138 word types, 7000000 tags\n",
      "2020-10-25 23:08:42,397 : INFO : PROGRESS: at example #7010000, processed 559623219 words (6406541/s), 390399 word types, 7010000 tags\n",
      "2020-10-25 23:08:42,533 : INFO : collected 390577 word types and 7018019 unique tags from a corpus of 7018019 examples and 560443010 words\n",
      "2020-10-25 23:08:42,534 : INFO : Loading a fresh vocabulary\n",
      "2020-10-25 23:08:42,935 : INFO : effective_min_count=2 retains 245139 unique words (62% of original 390577, drops 145438)\n",
      "2020-10-25 23:08:42,936 : INFO : effective_min_count=2 leaves 560297572 word corpus (99% of original 560443010, drops 145438)\n",
      "2020-10-25 23:08:43,558 : INFO : deleting the raw counts dictionary of 390577 items\n",
      "2020-10-25 23:08:43,571 : INFO : sample=0.001 downsamples 33 most-common words\n",
      "2020-10-25 23:08:43,572 : INFO : downsampling leaves estimated 424303668 word corpus (75.7% of prior 560297572)\n",
      "2020-10-25 23:08:44,209 : INFO : estimated required memory for 245139 words and 50 dimensions: 1624228900 bytes\n",
      "2020-10-25 23:08:44,210 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=300, min_count=2, epochs=40, workers = 16, window = 10)\n",
    "model.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-26 12:32:21,380 : INFO : saving Doc2Vec object under patents_d2v.model, separately None\n",
      "2020-10-26 12:32:21,383 : INFO : storing np array 'syn1neg' to patents_d2v.model.trainables.syn1neg.npy\n",
      "2020-10-26 12:32:21,415 : INFO : storing np array 'vectors' to patents_d2v.model.wv.vectors.npy\n",
      "2020-10-26 12:32:21,451 : INFO : storing np array 'vectors_docs' to patents_d2v.model.docvecs.vectors_docs.npy\n",
      "2020-10-26 12:32:22,938 : INFO : saved patents_d2v.model\n"
     ]
    }
   ],
   "source": [
    "model.save(\"patents_d2v.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.252743\n",
      "[array([-0.28087735,  0.38621008,  0.8508384 ,  1.038248  ,  0.07309564,\n",
      "        1.1977931 , -0.5088015 , -1.8267745 ,  0.13977815, -1.8833544 ,\n",
      "       -0.39452165, -0.62033504,  0.24143456, -1.688273  , -1.0880688 ,\n",
      "       -0.10534336, -2.47248   ,  0.14199567,  0.16780388,  0.04640283,\n",
      "       -1.1132685 , -2.8003633 , -0.31105733, -0.33777684, -2.2041044 ,\n",
      "        1.3713781 ,  0.2356057 , -0.2390185 , -1.7446188 , -1.2072209 ,\n",
      "       -2.6661847 , -0.13144748,  0.14559008,  0.8166889 , -1.8442206 ,\n",
      "       -0.94594324, -1.9050679 , -0.09199888,  1.3757935 ,  0.5763035 ,\n",
      "        1.9986854 , -0.7205064 , -2.7098856 , -3.057     , -0.3758834 ,\n",
      "        1.6166793 ,  0.7956759 ,  0.496455  ,  0.88827294, -0.35504362],\n",
      "      dtype=float32), array([ 0.7498945 , -0.2488806 , -0.04200224, -2.1140752 , -0.5353309 ,\n",
      "        0.18104102,  0.03363936,  1.0553697 ,  1.4649472 , -0.9062824 ,\n",
      "        0.60248774,  0.8979739 , -0.18848997, -1.6236618 , -0.22950743,\n",
      "        0.6535997 ,  0.2749011 ,  0.47743586, -0.919302  , -0.73954666,\n",
      "       -0.6959767 ,  0.5622273 , -1.7996339 ,  1.7468634 , -0.2886727 ,\n",
      "       -0.3723465 , -2.4439673 , -0.17260946, -2.1921327 ,  0.20723286,\n",
      "       -2.1549332 , -0.05721907,  1.9346466 ,  1.0029827 , -1.291375  ,\n",
      "       -0.7912599 , -0.88256645,  1.1814384 ,  0.9841466 , -0.33460844,\n",
      "        0.34545532,  1.3822756 , -0.67686284, -0.5253376 ,  0.3013683 ,\n",
      "        0.7566917 , -1.1456783 , -0.97011966,  1.3614997 ,  0.91839445],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import numpy.linalg as la\n",
    "\n",
    "doc = [\"Circular knitting machine. To permit selective needle projection, under control of a patterning arrangement, the needle jacks are made for rocking movement about an axis transverse to the direction of needle projection during knitting, and the camming system for the needle jacks is formed with two tracks, located one above the other (by a deeper cut, or camming elements of different heights) or, longitudinally staggered, one adjacent to the other, the cam tracks being arranged for selected projection of the needles to tuck or knit position.\",\n",
    "       #\"A method and apparatus scedhule uplink transmissions with reduced latency.\"\n",
    "       #\"according to all known laws of aviation, there is no way a bee should be able to fly. Its wings are too small to get\"\n",
    "        #+ \"its fat little body off the ground.\"\n",
    "       \"Self balancing table. In a circular knitting machine, a self-balancing, circular bobbin table which has formed therein a circular groove within which a plurality of balls freely roll to dynamically balance the table as it is rotated during the knitting operations.\"\n",
    "      ]\n",
    "str_vec = [doc[i].split(\" \") for i in range(len(doc))]\n",
    "vector = [model.infer_vector(i) for i in str_vec]\n",
    "normed_vec = [i/la.norm(i) for i in vector]\n",
    "\n",
    "print(np.dot(normed_vec[0], normed_vec[1]))\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Mary', 'had', 'a', 'little', 'lamb'], ['A', 'little', 'lamb', 'had', 'Mary']]\n",
      "0.95729846\n",
      "[array([-0.44410354, -0.13347703, -0.04725597,  0.1758879 , -0.3121682 ,\n",
      "       -0.18816602,  0.4953201 , -0.00496292, -0.29904738,  0.1341791 ,\n",
      "        0.64246714,  0.29677597,  0.03050934, -0.2745325 ,  0.16800937,\n",
      "        0.27837908,  0.6460266 , -0.64909667,  0.00759146, -0.80458236,\n",
      "       -0.92419046, -0.07583129, -0.0360688 ,  0.11015264,  0.59309864,\n",
      "        0.27324286,  0.8246222 ,  0.19211707,  0.26320645,  0.21116605,\n",
      "       -0.16574436, -0.53247976, -0.71851504, -0.25713804, -0.42713666,\n",
      "        0.15142445,  0.18009858, -0.08587842,  0.48084018,  0.27250993,\n",
      "       -0.15549062,  0.03779576, -0.3705872 , -0.2828869 , -0.06823739,\n",
      "        0.11681806,  0.22616307,  0.3048242 ,  0.06752926,  0.05729926],\n",
      "      dtype=float32), array([-0.27283373, -0.1134159 , -0.08214434,  0.12623751, -0.5206901 ,\n",
      "       -0.11811545,  0.519865  ,  0.06701396, -0.2987128 ,  0.20219547,\n",
      "        0.5933177 ,  0.11436074,  0.12182155, -0.1640929 , -0.01358714,\n",
      "        0.36158526,  0.80417985, -0.54930705,  0.01292388, -0.68216467,\n",
      "       -0.7151775 , -0.01789074, -0.20312753, -0.04439639,  0.4626386 ,\n",
      "        0.12887657,  1.0027734 ,  0.19839588,  0.36365402,  0.19684774,\n",
      "       -0.30749995, -0.70032704, -0.7698433 , -0.30020913, -0.4729004 ,\n",
      "        0.08826699,  0.08813883,  0.03636564,  0.6139429 ,  0.20925446,\n",
      "       -0.12624443,  0.13759328, -0.43142876, -0.34578258, -0.12015055,\n",
      "       -0.00700815,  0.06380522,  0.19069384,  0.06357578,  0.02608349],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import numpy.linalg as la\n",
    "\n",
    "doc = [\"Mary had a little lamb\", \"A little lamb had Mary\"]\n",
    "str_vec = [doc[i].split(\" \") for i in range(len(doc))]\n",
    "#str_vec = train_corpus[:2]\n",
    "print(str_vec)\n",
    "vector = [model.infer_vector(i) for i in str_vec]\n",
    "normed_vec = [i/la.norm(i) for i in vector]\n",
    "\n",
    "print(np.dot(normed_vec[0], normed_vec[1]))\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                      | 0/7018019 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-85d6ee6e112a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdoc_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_corpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0minferred_vector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfer_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_corpus\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdoc_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0msims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdocvecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minferred_vector\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdocvecs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mrank\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdocid\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdocid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msim\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msims\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mranks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\pure_patents\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[1;34m(self, positive, negative, topn, clip_start, clip_end, indexer)\u001b[0m\n\u001b[0;32m   1743\u001b[0m         \u001b[0mbest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdists\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtopn\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_docs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1744\u001b[0m         \u001b[1;31m# ignore (don't return) docs from the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1745\u001b[1;33m         result = [\n\u001b[0m\u001b[0;32m   1746\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_to_doctag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msim\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mclip_start\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moffset2doctag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_rawint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdists\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msim\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1747\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0msim\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\pure_patents\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1744\u001b[0m         \u001b[1;31m# ignore (don't return) docs from the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m         result = [\n\u001b[1;32m-> 1746\u001b[1;33m             \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_to_doctag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msim\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mclip_start\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moffset2doctag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_rawint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdists\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msim\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1747\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0msim\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1748\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msim\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mclip_start\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_docs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\pure_patents\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m_index_to_doctag\u001b[1;34m(i_index, offset2doctag, max_rawint)\u001b[0m\n\u001b[0;32m   1927\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mmax_rawint\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdoctags\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1929\u001b[1;33m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1930\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_index_to_doctag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset2doctag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_rawint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1931\u001b[0m         \u001b[1;34m\"\"\"Get string key for given `i_index`, if available. Otherwise return raw int doctag (same int).\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in tqdm(range(len(train_corpus))):\n",
    "    inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "\n",
    "    second_ranks.append(sims[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "counter = collections.Counter(ranks)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
